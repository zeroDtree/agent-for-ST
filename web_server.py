#!/usr/bin/env python3
"""
WebæœåŠ¡å™¨ - ä¸ºå‰ç«¯æä¾›APIæ¥å£ä¸agentäº¤äº’
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import json
import os
import queue
import argparse

# å¯¼å…¥ç°æœ‰çš„agentç³»ç»Ÿ
from main import create_graph
from states.state import State
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from config.config import CONFIG
from utils.logger import logger
from utils.singleton_dict import get_monitored_dict, add_dict_observer, get_dict_history

# from utils.preset import preset_messages

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# å…¨å±€å˜é‡æ¥å­˜å‚¨agentå›¾å’Œå¾…ç¡®è®¤çš„å‘½ä»¤
agent_graph = None

# ä½¿ç”¨å•ä¾‹å­—å…¸ç®¡ç†å™¨åˆ›å»ºè¢«ç›‘æ§çš„å­—å…¸
pending_confirmations = get_monitored_dict(
    "pending_confirmations"
)  # å­˜å‚¨å¾…ç¡®è®¤çš„å‘½ä»¤: {session_id: {command: str, callback: callable}}
sse_clients = get_monitored_dict("sse_clients")  # å­˜å‚¨SSEå®¢æˆ·ç«¯è¿æ¥: {session_id: [client_generators, ...]}


def initialize_agent(web_mode=True):
    """åˆå§‹åŒ–agentå›¾"""
    global agent_graph
    try:
        agent_graph = create_graph(web_mode=web_mode)

        # è®¾ç½®å­—å…¸è§‚å¯Ÿè€…
        setup_dict_observers()

        logger.info(f"Agentç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ (Webæ¨¡å¼: {'å¯ç”¨' if web_mode else 'ç¦ç”¨'})")
        return True
    except Exception as e:
        logger.error(f"Agentç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def setup_dict_observers():
    """è®¾ç½®å­—å…¸ä¿®æ”¹è§‚å¯Ÿè€…"""

    def on_pending_confirmations_change(dict_name, operation, key, value, old_value):
        """pending_confirmations å­—å…¸ä¿®æ”¹æ—¶çš„å›è°ƒ"""
        if operation == "set" and old_value is None:
            logger.info(f"æ–°å¢å¾…ç¡®è®¤å‘½ä»¤: session_id={key}, command={value.get('command', 'unknown')}")
        elif operation == "delete":
            logger.info(f"ç§»é™¤å¾…ç¡®è®¤å‘½ä»¤: session_id={key}")

    def on_sse_clients_change(dict_name, operation, key, value, old_value):
        """sse_clients å­—å…¸ä¿®æ”¹æ—¶çš„å›è°ƒ"""
        if operation == "set":
            if old_value is None:
                logger.info(f"æ–°å¢SSEå®¢æˆ·ç«¯è¿æ¥: session_id={key}, å®¢æˆ·ç«¯æ•°é‡={len(value) if value else 0}")
            else:
                logger.info(f"æ›´æ–°SSEå®¢æˆ·ç«¯è¿æ¥: session_id={key}, å®¢æˆ·ç«¯æ•°é‡={len(value) if value else 0}")
        elif operation == "delete":
            logger.info(f"ç§»é™¤SSEå®¢æˆ·ç«¯è¿æ¥: session_id={key}")

    # æ·»åŠ è§‚å¯Ÿè€…
    add_dict_observer("pending_confirmations", on_pending_confirmations_change)
    add_dict_observer("sse_clients", on_sse_clients_change)


@app.route("/api/health", methods=["GET"])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({"status": "ok", "agent_ready": agent_graph is not None, "message": "AI Agent WebæœåŠ¡æ­£å¸¸è¿è¡Œ"})


@app.route("/api/dict-history", methods=["GET"])
def get_dict_modification_history():
    """è·å–å­—å…¸ä¿®æ”¹å†å²"""
    try:
        dict_name = request.args.get("dict_name")  # å¯é€‰å‚æ•°ï¼ŒæŒ‡å®šå­—å…¸åç§°
        limit = int(request.args.get("limit", 50))  # é™åˆ¶è¿”å›æ•°é‡ï¼Œé»˜è®¤50

        history = get_dict_history(dict_name, limit)

        # æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»æ ¼å¼
        import datetime

        for record in history:
            record["readable_time"] = datetime.datetime.fromtimestamp(record["timestamp"]).strftime("%Y-%m-%d %H:%M:%S")

        return jsonify(
            {"status": "success", "history": history, "total_records": len(history), "dict_name": dict_name or "all"}
        )

    except Exception as e:
        logger.error(f"è·å–å­—å…¸ä¿®æ”¹å†å²æ—¶å‡ºé”™: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/dict-status", methods=["GET"])
def get_dict_status():
    """è·å–æ‰€æœ‰å­—å…¸çš„çŠ¶æ€ä¿¡æ¯"""
    try:
        from utils.singleton_dict import dict_manager

        all_dicts = dict_manager.get_all_dict_names()
        dict_status = {}

        for dict_name in all_dicts:
            info = dict_manager.get_dict_info(dict_name)
            dict_status[dict_name] = info

        return jsonify({"status": "success", "dictionaries": dict_status, "total_dicts": len(all_dicts)})

    except Exception as e:
        logger.error(f"è·å–å­—å…¸çŠ¶æ€æ—¶å‡ºé”™: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/pending-confirmations", methods=["GET"])
def get_pending_confirmations():
    """è·å–å¾…ç¡®è®¤çš„å‘½ä»¤åˆ—è¡¨"""
    session_id = request.args.get("session_id", "default")
    if session_id in pending_confirmations:
        return jsonify(
            {
                "status": "success",
                "pending": True,
                "command": pending_confirmations[session_id]["command"],
                "tool_name": pending_confirmations[session_id].get("tool_name", "unknown"),
                "session_id": session_id,
            }
        )
    else:
        return jsonify({"status": "success", "pending": False, "session_id": session_id})


@app.route("/api/confirm-command", methods=["POST"])
def confirm_command():
    """ç¡®è®¤æˆ–æ‹’ç»å‘½ä»¤æ‰§è¡Œ"""
    try:
        data = request.get_json()
        session_id = data.get("session_id", "default")
        confirmed = data.get("confirmed", False)

        if session_id not in pending_confirmations:
            return jsonify({"status": "error", "message": "æ²¡æœ‰æ‰¾åˆ°å¾…ç¡®è®¤çš„å‘½ä»¤"}), 404

        # è·å–å›è°ƒå‡½æ•°
        callback = pending_confirmations[session_id]["callback"]
        command = pending_confirmations[session_id]["command"]

        # æ¸…é™¤å¾…ç¡®è®¤çŠ¶æ€
        del pending_confirmations[session_id]

        # æ‰§è¡Œå›è°ƒ
        if callback:
            callback(confirmed)

        logger.info(f"ç”¨æˆ·{'ç¡®è®¤' if confirmed else 'æ‹’ç»'}æ‰§è¡Œå‘½ä»¤: {command}")

        return jsonify(
            {"status": "success", "message": f"å‘½ä»¤å·²{'ç¡®è®¤' if confirmed else 'æ‹’ç»'}", "confirmed": confirmed}
        )

    except Exception as e:
        logger.error(f"å¤„ç†å‘½ä»¤ç¡®è®¤æ—¶å‡ºé”™: {e}")
        return jsonify({"status": "error", "message": str(e)}), 500


@app.route("/api/events", methods=["GET"])
def events():
    """Server-Sent Eventsæ¥å£ï¼Œç”¨äºæ¨é€ç¡®è®¤è¯·æ±‚"""
    session_id = request.args.get("session_id", "default")

    def event_stream():
        # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
        yield f"data: {json.dumps({'type': 'connected', 'session_id': session_id})}\n\n"

        # åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—æ¥æ¥æ”¶äº‹ä»¶
        event_queue = queue.Queue()
        # å°†æ­¤å®¢æˆ·ç«¯æ·»åŠ åˆ°å…¨å±€å®¢æˆ·ç«¯åˆ—è¡¨
        if session_id not in sse_clients:
            sse_clients[session_id] = []
        sse_clients[session_id].append(event_queue)
        print(f"SSEå®¢æˆ·ç«¯å·²æ³¨å†Œ: {session_id}, å½“å‰å®¢æˆ·ç«¯æ•°: {len(sse_clients[session_id])}")
        print(f"æ‰€æœ‰ä¼šè¯: {list(sse_clients.keys())}")
        print(f"SSEå®¢æˆ·ç«¯: {sse_clients}")

        try:
            while True:
                try:
                    # ç­‰å¾…äº‹ä»¶ï¼Œè®¾ç½®è¶…æ—¶ä»¥ä¾¿å®šæœŸå‘é€å¿ƒè·³
                    event = event_queue.get(timeout=30)
                    yield f"data: {json.dumps(event)}\n\n"
                except queue.Empty:
                    # å‘é€å¿ƒè·³ä¿æŒè¿æ¥
                    yield f"data: {json.dumps({'type': 'heartbeat'})}\n\n"
                except GeneratorExit:
                    break
        finally:
            # æ¸…ç†å®¢æˆ·ç«¯è¿æ¥
            if session_id in sse_clients and event_queue in sse_clients[session_id]:
                sse_clients[session_id].remove(event_queue)
                if not sse_clients[session_id]:
                    print(f"SSEå®¢æˆ·ç«¯å·²æ¸…ç†: {session_id}")
                    del sse_clients[session_id]

    return app.response_class(
        event_stream(),
        mimetype="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control",
        },
    )


def send_sse_event(session_id: str, event_data: dict):
    """å‘æŒ‡å®šä¼šè¯çš„æ‰€æœ‰SSEå®¢æˆ·ç«¯å‘é€äº‹ä»¶"""
    print(f"å‡†å¤‡å‘é€SSEäº‹ä»¶: {event_data}")
    print(f"SSEå®¢æˆ·ç«¯: {sse_clients}")
    print(f"ä¼šè¯ID: {session_id}")

    if session_id in sse_clients:
        dead_clients = []
        for client_queue in sse_clients[session_id]:
            try:
                print(f"å‘é€SSEäº‹ä»¶: {event_data}")
                client_queue.put(event_data, timeout=1)
            except queue.Full:
                # å®¢æˆ·ç«¯é˜Ÿåˆ—æ»¡ï¼Œå¯èƒ½å·²æ–­å¼€è¿æ¥
                dead_clients.append(client_queue)
            except Exception as e:
                logger.warning(f"å‘é€SSEäº‹ä»¶å¤±è´¥: {e}")
                dead_clients.append(client_queue)

        # æ¸…ç†å·²æ–­å¼€çš„å®¢æˆ·ç«¯
        for dead_client in dead_clients:
            if dead_client in sse_clients[session_id]:
                sse_clients[session_id].remove(dead_client)


def process_message(messages: list, session_id: str = "default") -> str:
    """å¤„ç†å®Œæ•´å¯¹è¯å†å²å¹¶è¿”å›agentå“åº”"""
    try:
        # å°†OpenAIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºLangChainæ ¼å¼
        langchain_messages = []

        # æ·»åŠ preset_messagesä½œä¸ºç³»ç»Ÿä¸Šä¸‹æ–‡
        # langchain_messages.extend(preset_messages)

        # è½¬æ¢å¯¹è¯å†å²
        for msg in messages:
            role = msg.get("role", "")
            content = msg.get("content", "")

            if role == "user":
                langchain_messages.append(HumanMessage(content=content))
            elif role == "assistant":
                langchain_messages.append(AIMessage(content=content))
            elif role == "system":
                langchain_messages.append(SystemMessage(content=content))

        # æ„å»ºè¾“å…¥çŠ¶æ€
        input_state = {
            "messages": langchain_messages,
            "session_id": session_id,
        }

        # è°ƒç”¨agentå¤„ç†ï¼ˆæ— çŠ¶æ€ï¼‰
        events = agent_graph.stream(
            input=input_state,
            config={
                "recursion_limit": CONFIG["recursion_limit"],
            },
            stream_mode=CONFIG["stream_mode"],
        )

        # æ”¶é›†å“åº”
        response_messages = []
        for event in events:
            if event.get("messages") and len(event["messages"]) > 0:
                response_messages.extend(event["messages"])

        # æå–æœ€åçš„AIå“åº”
        if response_messages:
            last_message = response_messages[-1]
            if isinstance(last_message, AIMessage):
                return last_message.content
            else:
                return str(last_message.content)
        else:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"

    except Exception as e:
        logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
        raise e


def get_timestamp():
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    from datetime import datetime

    return datetime.now().isoformat()


# ==================== OpenAIå…¼å®¹API ====================


@app.route("/v1/chat/completions", methods=["POST"])
def openai_chat_completions():
    """OpenAIå…¼å®¹çš„èŠå¤©å®Œæˆæ¥å£ï¼Œç”¨äºSillyTaverné›†æˆ"""
    try:
        data = request.get_json()

        # è·å–è¯·æ±‚å‚æ•°
        messages = data.get("messages", [])
        model = data.get("model", "my-agent")
        stream = data.get("stream", False)
        max_tokens = data.get("max_tokens", 2000)
        temperature = data.get("temperature", 0.7)

        if not messages:
            return jsonify({"error": {"message": "messages cannot be empty", "type": "invalid_request_error"}}), 400

        if not agent_graph:
            return jsonify({"error": {"message": "Agent system not initialized", "type": "internal_server_error"}}), 500

        # æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        user_message = ""
        for msg in reversed(messages):
            if msg.get("role") == "user":
                user_message = msg.get("content", "")
                break

        if not user_message:
            return jsonify({"error": {"message": "No user message found", "type": "invalid_request_error"}}), 400

        logger.info(f"OpenAI APIè¯·æ±‚ - æ¨¡å‹: {model}, ç”¨æˆ·æ¶ˆæ¯: {user_message[:100]}...")

        # ä»è¯·æ±‚å¤´æˆ–å‚æ•°ä¸­è·å–session_id
        session_id = request.headers.get("X-Session-ID", "default")
        print(f"æ”¶åˆ°èŠå¤©è¯·æ±‚ - ä¼šè¯ID: {session_id}")
        print(f"è¯·æ±‚å¤´: {dict(request.headers)}")

        if stream:
            # æµå¼å“åº”
            return handle_streaming_response(model, messages, session_id)
        else:
            # éæµå¼å“åº”
            return handle_non_streaming_response(model, messages, session_id)

    except Exception as e:
        logger.error(f"å¤„ç†OpenAI APIè¯·æ±‚æ—¶å‡ºé”™: {e}")
        return jsonify({"error": {"message": str(e), "type": "internal_server_error"}}), 500


def handle_non_streaming_response(model: str, original_messages: list, session_id: str = "default"):
    """å¤„ç†éæµå¼å“åº”"""
    try:
        # å¤„ç†æ¶ˆæ¯
        response_content = process_message(original_messages, session_id)

        # æ„å»ºOpenAIå…¼å®¹çš„å“åº”æ ¼å¼
        import uuid

        completion_id = str(uuid.uuid4())[:8]
        response = {
            "id": f"chatcmpl-{completion_id}",
            "object": "chat.completion",
            "created": int(get_timestamp_unix()),
            "model": model,
            "choices": [
                {"index": 0, "message": {"role": "assistant", "content": response_content}, "finish_reason": "stop"}
            ],
            "usage": {
                "prompt_tokens": estimate_tokens(str(original_messages)),
                "completion_tokens": estimate_tokens(response_content),
                "total_tokens": estimate_tokens(str(original_messages)) + estimate_tokens(response_content),
            },
        }

        return jsonify(response)

    except Exception as e:
        logger.error(f"å¤„ç†éæµå¼å“åº”æ—¶å‡ºé”™: {e}")
        return jsonify({"error": {"message": str(e), "type": "internal_server_error"}}), 500


def handle_streaming_response(model: str, messages: list, session_id: str = "default"):
    """å¤„ç†æµå¼å“åº”"""
    try:
        from flask import Response
        import uuid
        import json

        def generate():
            try:
                # å°†OpenAIæ ¼å¼çš„æ¶ˆæ¯è½¬æ¢ä¸ºLangChainæ ¼å¼
                langchain_messages = []

                # æ·»åŠ preset_messagesä½œä¸ºç³»ç»Ÿä¸Šä¸‹æ–‡
                # langchain_messages.extend(preset_messages)

                # è½¬æ¢å¯¹è¯å†å²
                for msg in messages:
                    role = msg.get("role", "")
                    content = msg.get("content", "")

                    if role == "user":
                        langchain_messages.append(HumanMessage(content=content))
                    elif role == "assistant":
                        langchain_messages.append(AIMessage(content=content))
                    elif role == "system":
                        langchain_messages.append(SystemMessage(content=content))

                # æ„å»ºè¾“å…¥çŠ¶æ€
                input_state = {
                    "messages": langchain_messages,
                    "session_id": session_id,
                }

                completion_id = str(uuid.uuid4())[:8]

                # å‘é€å¼€å§‹äº‹ä»¶
                start_chunk = {
                    "id": f"chatcmpl-{completion_id}",
                    "object": "chat.completion.chunk",
                    "created": int(get_timestamp_unix()),
                    "model": model,
                    "choices": [{"index": 0, "delta": {"role": "assistant"}, "finish_reason": None}],
                }
                yield f"data: {json.dumps(start_chunk)}\n\n"

                # æµå¼å¤„ç†agentå“åº”
                accumulated_content = ""

                events = agent_graph.stream(
                    input=input_state,
                    config={
                        "recursion_limit": CONFIG["recursion_limit"],
                    },
                    stream_mode="messages",  # ä½¿ç”¨messagesæ¨¡å¼è·å¾—æ›´ç»†ç²’åº¦çš„æµå¼è¾“å‡º
                )

                for message_chunk, metadata in events:
                    if message_chunk.content and metadata["langgraph_node"] not in ["my_tools"]:
                        accumulated_content = message_chunk.content

                        chunk = {
                            "id": f"chatcmpl-{completion_id}",
                            "object": "chat.completion.chunk",
                            "created": int(get_timestamp_unix()),
                            "model": model,
                            "choices": [{"index": 0, "delta": {"content": accumulated_content}, "finish_reason": None}],
                        }
                        yield f"data: {json.dumps(chunk)}\n\n"

                # å‘é€ç»“æŸäº‹ä»¶
                end_chunk = {
                    "id": f"chatcmpl-{completion_id}",
                    "object": "chat.completion.chunk",
                    "created": int(get_timestamp_unix()),
                    "model": model,
                    "choices": [{"index": 0, "delta": {}, "finish_reason": "stop"}],
                }
                yield f"data: {json.dumps(end_chunk)}\n\n"

                # å‘é€ç»“æŸæ ‡è®°
                yield "data: [DONE]\n\n"

            except Exception as e:
                logger.error(f"æµå¼å“åº”ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                # å‘é€é”™è¯¯ä¿¡æ¯
                error_chunk = {
                    "id": f"chatcmpl-error",
                    "object": "chat.completion.chunk",
                    "created": int(get_timestamp_unix()),
                    "model": model,
                    "choices": [
                        {
                            "index": 0,
                            "delta": {"content": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}"},
                            "finish_reason": "stop",
                        }
                    ],
                }
                yield f"data: {json.dumps(error_chunk)}\n\n"
                yield "data: [DONE]\n\n"

        return Response(
            generate(),
            mimetype="text/plain",
            headers={
                "Content-Type": "text/event-stream",
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "Content-Type",
            },
        )

    except Exception as e:
        logger.error(f"å¤„ç†æµå¼å“åº”æ—¶å‡ºé”™: {e}")
        return jsonify({"error": {"message": str(e), "type": "internal_server_error"}}), 500


@app.route("/v1/models", methods=["GET"])
def list_models():
    """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹ï¼ˆOpenAIå…¼å®¹æ¥å£ï¼‰"""
    return jsonify(
        {
            "object": "list",
            "data": [
                {
                    "id": "my-agent",
                    "object": "model",
                    "created": int(get_timestamp_unix()),
                    "owned_by": "my-agent-system",
                    "permission": [],
                    "root": "my-agent",
                    "parent": None,
                }
            ],
        }
    )


def estimate_tokens(text: str) -> int:
    """ç®€å•çš„tokenæ•°é‡ä¼°ç®—ï¼ˆå¤§çº¦1token=4å­—ç¬¦ï¼‰"""
    if not text:
        return 0
    return max(1, len(text) // 4)


def get_timestamp_unix():
    """è·å–Unixæ—¶é—´æˆ³"""
    from datetime import datetime

    return int(datetime.now().timestamp())


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="AI Agent WebæœåŠ¡å™¨ - æä¾›OpenAIå…¼å®¹çš„APIæ¥å£",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s                          # ä½¿ç”¨é»˜è®¤é…ç½®å¯åŠ¨
  %(prog)s --port 8080              # åœ¨8080ç«¯å£å¯åŠ¨
  %(prog)s --host 127.0.0.1         # ä»…å…è®¸æœ¬åœ°è®¿é—®
  %(prog)s --debug                  # å¯ç”¨è°ƒè¯•æ¨¡å¼
  %(prog)s --no-web-mode            # ç¦ç”¨Webæ¨¡å¼
  %(prog)s --port 8080 --debug      # åœ¨8080ç«¯å£å¯åŠ¨å¹¶å¯ç”¨è°ƒè¯•æ¨¡å¼
        """
    )
    
    # æœåŠ¡å™¨é…ç½®å‚æ•°
    parser.add_argument(
        "--host", 
        type=str, 
        default="0.0.0.0",
        help="æœåŠ¡å™¨ç›‘å¬çš„ä¸»æœºåœ°å€ (é»˜è®¤: 0.0.0.0)"
    )
    
    parser.add_argument(
        "--port", 
        type=int, 
        default=5000,
        help="æœåŠ¡å™¨ç›‘å¬çš„ç«¯å£å· (é»˜è®¤: 5000)"
    )
    
    parser.add_argument(
        "--debug", 
        action="store_true",
        help="å¯ç”¨Flaskè°ƒè¯•æ¨¡å¼ (é»˜è®¤: å…³é—­)"
    )
    
    parser.add_argument(
        "--no-debug", 
        action="store_true",
        help="å¼ºåˆ¶ç¦ç”¨è°ƒè¯•æ¨¡å¼"
    )
    
    # Agenté…ç½®å‚æ•°
    parser.add_argument(
        "--web-mode", 
        action="store_true", 
        default=True,
        help="å¯ç”¨Webæ¨¡å¼ (é»˜è®¤: å¯ç”¨)"
    )
    
    parser.add_argument(
        "--no-web-mode", 
        action="store_true",
        help="ç¦ç”¨Webæ¨¡å¼"
    )
    
    # æ—¥å¿—é…ç½®å‚æ•°
    parser.add_argument(
        "--log-level", 
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        default="INFO",
        help="è®¾ç½®æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)"
    )
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument(
        "--version", 
        action="version", 
        version="AI Agent Web Server v1.0.0"
    )
    
    args = parser.parse_args()
    
    # å¤„ç†äº’æ–¥é€‰é¡¹
    if args.no_debug:
        args.debug = False
    
    if args.no_web_mode:
        args.web_mode = False
    
    return args


if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.getLogger().setLevel(getattr(logging, args.log_level))
    logger.setLevel(getattr(logging, args.log_level))
    
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print("ğŸš€ å¯åŠ¨AI Agent APIæœåŠ¡å™¨ (SillyTavernå…¼å®¹)...")
    print(f"ğŸ“¡ æœåŠ¡å™¨åœ°å€: {args.host}:{args.port}")
    print(f"ğŸŒ OpenAI API: http://{args.host}:{args.port}/v1/chat/completions")
    print(f"ğŸ“Š å¥åº·æ£€æŸ¥: http://{args.host}:{args.port}/api/health")
    print(f"ğŸ”§ è°ƒè¯•æ¨¡å¼: {'å¯ç”¨' if args.debug else 'ç¦ç”¨'}")
    print(f"ğŸŒ Webæ¨¡å¼: {'å¯ç”¨' if args.web_mode else 'ç¦ç”¨'}")
    print(f"ğŸ“ æ—¥å¿—çº§åˆ«: {args.log_level}")
    print()
    
    # åˆå§‹åŒ–agentç³»ç»Ÿ
    if initialize_agent(web_mode=args.web_mode):
        logger.info(f"æ­£åœ¨å¯åŠ¨WebæœåŠ¡å™¨ {args.host}:{args.port}")
        
        try:
            # å¯åŠ¨æœåŠ¡å™¨
            app.run(
                host=args.host, 
                port=args.port, 
                debug=args.debug,
                use_reloader=False  # é¿å…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹é‡å¤åˆå§‹åŒ–
            )
        except KeyboardInterrupt:
            print("\nğŸ‘‹ æœåŠ¡å™¨å·²åœæ­¢")
            logger.info("æœåŠ¡å™¨æ”¶åˆ°åœæ­¢ä¿¡å·")
        except Exception as e:
            print(f"âŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
            logger.error(f"æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
    else:
        print("âŒ Agentç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨WebæœåŠ¡å™¨")
        exit(1)
